---
title: Troubleshooting On-Demand RabbitMQ for PCF
owner: London Services Enablement
---

<style>
    .note.warning {
        background-color: #fdd;
        border-color: #fbb
    }

    .note.warning:before {
        color: #f99;
    }
</style>

This topic provides operators with basic instructions for troubleshooting on-demand RabbitMQ&reg; for Pivotal Cloud Foundry (PCF).

## <a id="errors"></a>Troubleshooting Errors

Start here if you're responding to a specific errors or error messages.

### <a id="install-fail"></a>Failed Install

1. Certificate issues: The on-demand broker (ODB) requires valid certificates. Ensure that your certificates are valid and [generate new ones](http://docs.pivotal.io/p-mysql/credential-rotation.html) if necessary. 
1. Deploy fails: Deploys can fail for a variety of reasons. View the logs using Ops Manager to determine why the deploy is failing.
1. [Networking problems](#network): 
    - Cloud Foundry cannot reach the service broker
    - Cloud Foundry cannot reach the service instances
    - The service network cannot access the BOSH director 
1. [Register broker errand](#register-broker) fails.
1. The smoke test errand fails.
1. Resource sizing issues: These occur when the resource sizes selected for a given plan are less than the service requires to function. Check your resource configuration in Ops Manager and ensure that the configuration matches that recommended by the service.
1. Other service-specific issues.

### <a id="cannot-create-delete"></a>Cannot Create or Delete Service Instances

If developers report errors such as the following:

<pre class="terminal">
Instance provisioning failed: There was a problem completing your request. Please contact your operations team providing the following information: service: redis-acceptance, service-instance-guid: ae9e232c-0bd5-4684-af27-1b08b0c70089, broker-request-id: 63da3a35-24aa-4183-aec6-db8294506bac, task-id: 442, operation: create
</pre>

[Log in to BOSH](https://docs.pivotal.io/pivotalcf/customizing/trouble-advanced.html#prepare) and target the service instance using the instructions on [parsing a Cloud Foundry error message](#parse-error).

Retrieve the BOSH task ID from the error message and run
`bosh task TASK-ID`.

If the BOSH error shows a problem with the deployment manifest:

  1. Download the manifest for the service instance by running `bosh download manifest SERVICE-INSTANCE-GUID MY-SERVICE.yml`.
  1. Check the manifest for configuration errors.

[Access the broker logs](#access-broker)  and use the `broker-request-id` from the error message above to search the log for more information.

Check for:

  - [Authentication errors](#auth)

  - [Network errors](#network)

  - [Quota errors](#quotas) 

### <a id="timeouts"></a> Broker Request Timeouts

If developers report errors such as:

<pre class="terminal">
Server error, status code: 504, error code: 10001, message: The request to the service broker timed out: https://BROKER-URL/v2/service_instances/e34046d3-2379-40d0-a318-d54fc7a5b13f/service_bindings/aa635a3b-ef6d-41c3-a23f-55752f3f651b
</pre>

1. Validate that Cloud Foundry (CF) has [network connectivity to the service broker](#network). 
1. Check the BOSH queue size:
    - Log into BOSH as the admin user
    - Run `bosh tasks`
1. If there are a large number of queued tasks then the system may be under load. BOSH is configured with two workers and one status worker. Advise app developers to try again later once the system is under less load.

In the future, Ops Manager will support configuring the number of BOSH workers available to the system.

### <a id="cannot-bind"></a>Cannot Bind to or Unbind from Service Instances

#### <a id="instance-not-exist"></a>Instance Does Not Exist

If developers report errors such as:

<pre class="terminal">
Server error, status code: 502, error code: 10001, message: Service broker error: instance does not exist`
</pre>

1. Run `cf service MY-INSTANCE --guid` to check that the service instance exists in BOSH and CF.

1. Pre-pend the text `service_instance-` to the GUID you just obtained to create the ID that BOSH uses for your service instance (e.g. if your GUID is `1Hy6H`, this becomes `service_instance-1Hy6H`).

1. Run `bosh vms INSTANCE-GUID` with the service instance ID from the last step.

If the bosh deployment is not found then it has been deleted from BOSH. Contact Pivotal support for further assistance on recovery.

#### <a id="other-errors"></a>Other errors

If developers report errors such as:

<pre class="terminal">
Server error, status code: 502, error code: 10001, message: Service broker error: There was a problem completing your request. Please contact your operations team providing the following information: service: example-service, service-instance-guid: 8d69de6c-88c6-4283-b8bc-1c46103714e2, broker-request-id: 15f4f87e-200a-4b1a-b76c-1c4b6597c2e1, operation: bind
</pre>

To find out the exact issue with the binding process:

1. [Access the service broker logs](#access-broker).

1. Search the logs for the `broker-request-id` string listed in the error message above. 

1. Contact Pivotal support for further assistance if you are unable to resolve the problem.

1. Check for:
  - [Authentication errors](#auth)
  - [Network errors](#network)

### <a id="cannot-connect"></a>Cannot Connect to a Service Instance

If developers report that their app cannot use service instances that they have successfully created and bound:

Ask the user to send application logs that show the connection error. If the error is originating from the service, then follow service-specific instructions. If the issue appears to be network-related, then:

1. Check that [application security groups](https://docs.pivotal.io/pivotalcf/adminguide/app-sec-groups.html) are configured correctly.
Access should be configured for the service network that the tile is deployed to.

1. Ensure that the network the PCF Elastic Runtime tile is deployed to has network access to the service network. You can find the network definition for this service network in the Ops Manager Director tile.

1. In Ops Manager go into the service tile and see the service network that is configured in the networks tab.

1. In Ops Manager go into the ERT tile and see the network it is assigned to.
Make sure that these networks can access each other.

### <a id="upgrade-all-fails"></a>Upgrade All Instances Fails

If the [`upgrade-all-service-instances`](#upgrade-all) errand fails, look at the errand output in the Ops Manager log.

If an instance fails to upgrade, debug and fix it before running the errand again to prevent any failure issues from spreading to other on-demand instances.

Once the Ops Manager log no longer lists the deployment as `failing`, [re-run the errand](#upgrade-all) to upgrade the rest of the instances. 

### <a id="upgrade-all-too-long"></a>Upgrade All Instances Takes a Long Time

1. Depending on your IaaS and the number of service instances, the [`upgrade-all-service-instances`](#upgrade-all) task takes 15-20 minutes per instance if you changed IaaS resources and 5-10 minutes per instance if you reconfigured BOSH releases.
1. To calculate how long the errand should take, multiply the number of instances by 20 minutes. 
1. If the errand goes on for much longer than this, you may want to:
   - `ssh` onto the errand VM
   - `cd /var/vcap/sys/log` and look for the errand output log
   - `tail -f LOG` and see if the errand is still attempting to upgrade instances. If it is, then allow the errand to continue. If it appears to be stuck:
    - `bosh tasks` and identify the errand task
    - `bosh cancel task TASK-ID`
1. Retry [running the errand](#upgrade-all).

### <a id="missing-logs"></a>Missing Logs and Metrics

If no logs are being emitted by the on-demand broker, check that your syslog forwarding address is correct in Ops Manager.

1. Ensure you have configured syslog for the tile.
1. Ensure that you have network connectivity between the networks that the tile is using and the syslog destination. If the destination is external, you need to use the [public ip](https://docs.pivotal.io/svc-sdk/odb/0-14/tile.html#public-ip) VM extension feature available in your Ops Manager tile configuration settings.
1. Verify that the Firehose is emitting metrics:
    1. Install the [`cf nozzle` plugin](https://github.com/cloudfoundry/firehose-plugin)
    1. Run `cf nozzle -f ValueMetric | 
    grep --line-buffered "on-demand-broker/MY-SERVICE"` to find logs from your service in the `cf nozzle` output. 
</pre>

If no metrics appear within five minutes, verify that the broker network has access to the Loggregator system on all required ports.

[Contact Pivotal support](#support) if you are unable to resolve the issue. 

## <a id="components"></a>Troubleshooting Components

Guidance on checking for and fixing issues in on-demand service components.

### <a id="bosh"></a>BOSH problems

#### <a id="no-bosh-uuid"></a>Missing BOSH Director UUID

If using the BOSH v1 CLI you need to re-add the `director_uuid` to the manifest:

1. Run `bosh status --uuid` and record the `director_uuid` value from the output.

1. Edit the manifest and add the `director_uuid: DIRECTOR-UUID` from the last step at the top of the manifest.

For more, see [Deployment Identification](https://bosh.io/docs/manifest-v2.html#deployment) in the BOSH docs.

#### <a id="large-queue"></a>Large BOSH Queue

On-demand service brokers add tasks to the BOSH request queue, which can back up and cause delay under heavy loads. An app developer who requests a new service instance sees `create in progress` in the Cloud Foundry Command Line Interface (cf CLI) until BOSH processes the queued request.

Ops Manager currently deploys two BOSH workers to process its queue. Future versions of Ops Manager will let users configure the number of BOSH workers.

### <a id="bosh-config"></a>Configuration

#### <a id="bosh-instance-fail"></a>Service instances in failing state

You may have configured a VM / Disk type in tile plan page in Ops Manager that is insufficiently large for the service instance to start. See tile-specific guidance on resource requirements.

### <a id="auth"></a>Authentication

#### <a id="uaa-change"></a>UAA Changes

If you have rotated any UAA user credentials then you may see authentication issues in the service broker logs. 

To resolve this, redeploy the service tile in Ops Manager. This provides the broker with the latest configuration.

<p class="note"><strong>Note</strong>: You must ensure that any changes to UAA credentials are reflected in the OpsManager <code>credentials</code> tab of the Elastic Runtime tile.</p>

### <a id="network"></a>Networking

Common issues include:

1. Network latency when connecting to the service instance to create or delete a binding.  
  - Solution: Try again or improve network performance
1. Network firewall rules are blocking connections from the service broker to the service instance.  
  - Solution: Open the service tile in Ops Manager and check the two networks configured in the **Networks** pane. Ensure that these networks allow access to each other.
1. Network firewall rules are blocking connections from the service network to the BOSH director network.  
  - Solution: Ensure that service instances can access the Director so that the BOSH agents can report in.
1. Apps cannot access the service network.  
  - Solution: Configure Cloud Foundry application security groups to allow runtime access to the service network.
1. Problems accessing BOSH’s UAA or the BOSH director.  
  - Solution: Follow network troubleshooting and check that the BOSH director is online.

#### <a id="broker-to-instances"></a>Validate Service Broker Connectivity to Service Instances

To validate you can `bosh ssh` onto the service broker, download the broker manifest and target the deployment, then try to reach the service instance.

If no BOSH `task-id` appears in the error message, look in the broker log using the `broker-request-id` from the task.

#### <a id="app-to-instances"></a>Validate App Access to Service Instance

Use `cf ssh` to access to the app container, then try connecting to the service instance using the binding included in the `VCAP_SERVICES` environment variable.

### <a id="quotas"></a>Quotas

#### <a id="plan-quotas"></a>Plan Quota issues

If developers report errors such as:

<pre class="terminal">
Message: Service broker error: The quota for this service plan has been exceeded. 
Please contact your Operator for help.
</pre>

1. Check your current plan quota.
1. Increase the plan quota.
1. Log into Ops Manager.
1. Reconfigure the quota on the plan page.
1. Deploy the tile.
1. Find who is using the plan quota and take the appropriate action.

#### <a id="global-quotas"></a>Global Quota Issues

If developers report errors such as:

<pre class="terminal">
Message: Service broker error: The quota for this service has been exceeded. 
Please contact your Operator for help.
</pre>

1. Check your current global quota.
1. Increase the global quota.
1. Log into Ops Manager.
1. Reconfigure the quota on the on-demand settings page.
1. Deploy the tile.
1. Find out who is using the quota and take the appropriate action.

#### <a id="failing-jobs"></a>Failing jobs and unhealthy instances

To determine whether there is an issue with the service deployment, run `bosh vms`:

<pre class="terminal">
$ bosh vms --vitals service-instance_$guid
</pre>

For additional information, run `bosh instances`:

<pre class="terminal">
$ bosh instances --ps --vitals
</pre>

If the VM is failing. follow the service-specific information. Any unadvised corrective actions (such as running `bosh restart` on a VM) may cause issues in the service instance.

## <a id="techniques"></a>Techniques for Troubleshooting

Instructions on interacting with the on-demand service broker and on-demand service instance BOSH deployments, and on performing general maintenance and housekeeping tasks

### <a id="parse-error"></a>Parse a Cloud Foundry (CF) Error Message

Failed operations (create, update, bind, unbind, delete) result in an error message. You can retrieve the error message later by running the cf CLI command `cf service INSTANCE-NAME`.

<pre class="terminal">
$ cf service myservice

Service instance: myservice
Service: super-db
Bound apps:
Tags:
Plan: dedicated-vm
Description: Dedicated Instance
Documentation url:
Dashboard: 

Last Operation
Status: create failed
Message: Instance provisioning failed: There was a problem completing your request. 
     Please contact your operations team providing the following information: 
     service: redis-acceptance, 
     service-instance-guid: ae9e232c-0bd5-4684-af27-1b08b0c70089,
     broker-request-id: 63da3a35-24aa-4183-aec6-db8294506bac, 
     task-id: 442, 
     operation: create
Started: 2017-03-13T10:16:55Z
Updated: 2017-03-13T10:17:58Z
</pre>

Use the information in the `Message` field to debug further. Provide this information to Pivotal Support when filing a ticket.

The `task-id` field maps to the BOSH task id. For further information on a failed BOSH task, use the `bosh task TASK-ID` command in the BOSH CLI.

The `broker-request-guid` maps to the portion of the On-Demand Broker log containing the failed step. Access the broker log through your syslog aggregator, or access BOSH logs for the broker by typing `bosh logs broker 0`. If you have more than one broker instance, repeat this process for each instance.

### <a id="bosh-cf-access"></a>Access Broker and Instance Logs and VMs

Before following the procedures below, log into the [cf CLI](https://docs.pivotal.io/pivotalcf/cf-cli/getting-started.html) and the [BOSH CLI](https://docs.pivotal.io/pivotalcf/customizing/trouble-advanced.html#prepare).

#### <a id="access-broker"></a>Access Broker Logs and VM(s)

1. Run `bosh deployments` to identify the on-demand broker (ODB) deployment.
1. Run `bosh download manifest ODB-DEPLOYMENT-NAME odb.yml` to download the ODB manifest. 
1. Select the ODB deployment using `bosh deployment odb.yml`.
1. View VMs in the deployment using `bosh instances`.
1. Run `bosh ssh INSTANCE-ID` to SSH onto the VM.
1. Run `bosh logs INSTANCE-ID` to download broker logs.

You can also [access logs using Ops Manager](https://docs.pivotal.io/pivotalcf/customizing/troubleshooting.html#component_logs) by clicking on the **Logs** tab in the tile and downloading the broker logs.

The archive generated by BOSH or Ops Manager includes the following logs:

| **Log Name**          | **Description**                                                                                                                                                                                                  |
|-----------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **broker.log**        | Requests to the on-demand broker and the actions the broker performs while orchestrating the request (e.g. generating a manifest and calling BOSH). Start here when troubleshooting. |
| broker_ctl.log        | Control script logs for starting and stopping the on-demand broker.                                                                                                                                    |
| post-start.stderr.log | Errors that occur during post-start verification.                                                                                                                                                 |
| post-start.stdout.log | Post-start verification.                                                                                                                                                                              |

#### <a id="access-instance"></a>Access Service Instance Logs and VMs

1. To target an individual service instance deployment, retrieve the 
the GUID of your service instance with the cf CLI command `cf service MY-SERVICE --guid`.

1. Pre-pend the text `service_instance-` to the GUID you just obtained to create the ID that BOSH uses for your service instance (e.g. if your GUID is `1Hy6H`, this becomes `service_instance-1Hy6H`).

1. Run `bosh download manifest SERVICE-INSTANCE-GUID MY-SERVICE.yml` to download your BOSH manifest for the service.

1. Run `bosh deployment MY-SERVICE.yml to select the deployment`.

1. Run `bosh instances` to view VMs in the deployment.

1. Run `bosh ssh INSTANCE-ID` to SSH onto the VM.

1. Run `bosh logs INSTANCE-ID` to download instance logs.

### <a id="broker-errands"></a>Run Service Broker Errands to Manage Brokers and Instances

From the BOSH CLI, you can run service broker errands that manage the service brokers and perform mass operations on the service instances that the brokers created. These service broker errands include:

* [`register-broker`](#register-broker) registers a broker with the Cloud Controller and lists it in the Marketplace
* [`deregister-broker`](#deregister-broker) deregisters a broker with the Cloud Controller and removes it from the Marketplace
* [`upgrade-all-service-instances`](#upgrade-all) upgrades existing instances of a service to its latest installed version
* [`delete-all-service-instances`](#delete-all) deletes all instances of service
* [`orphan-deployments`](#detect-orphans) detects "orphan" instances that are running on BOSH but not registered with the Cloud Controller

Before running any of these errands, set the service broker manifest in the BOSH CLI by doing the following:

  1. Run `bosh deployments`.
  1. In the **Name** column of the output, look or `grep` for a string of the form `p-rabbit-GUID`. This is the unique identifier for the broker in BOSH.
  1. Run `bosh download manifest RABBIT-BROKER-GUID BROKER-MANIFEST.yml` with the unique string from the previous step and any filename you want to give the broker deployment manifest.
  1. Run `bosh deployment BROKER-MANIFEST.yml` to select the broker deployment as the one to run broker errands against.

#### <a id="register-broker"></a>Register Broker

This errand registers the broker with Cloud Foundry and enables access to plans in the service catalog. The errand should be run whenever the broker is re-deployed with new catalog metadata to update the Cloud Foundry catalog.

Plans with disabled service access are not visible to non-admin Cloud Foundry users (including Org Managers and Space Managers). Admin Cloud Foundry users can see all plans including those with disabled service access.

The errand does the following:

- Registers the service broker with Cloud Controller
- Enables service access for any plans that have the radio button set to `enabled` in the tile plan page.
- Disables service access for any plans that have the radio button set to `disabled` in the tile plan page.
- Does nothing for any for any plans that have the radio button set to `manual`

Run this errand with the command `bosh run errand register-broker` after you have selected the broker deployment with `bosh deployment`.

#### <a id="deregister-broker"></a>Deregister Broker

This errand deregisters a broker from Cloud Foundry. It requires that there are no existing service instances. You can use the [Delete All Service Instances errand](#delete-all) to delete any existing service instances that are problematic.

The errand does the following:

- Deletes the service broker from Cloud Controller
- Fails if there are any service instances, with or without bindings

Run this errand with the command `bosh run errand deregister-broker` after you have selected the broker deployment with `bosh deployment`.

#### <a id="upgrade-all"></a>Upgrade All Service Instances

If you have made changes to the plan definition or uploaded a new tile into OpsManager you may want to upgrade all the services to the latest software / plan definition. 

To do this you can either select the errand through the OpsManager UI and have this happen along with the `apply-changes` action or run the errand directly with the command `bosh run errand upgrade-all-service-instances` after you have selected the broker deployment with `bosh deployment`.

The errand does the following:

- Collects all of the service instances the on-demand broker has registered.
- For each instance the errand serially:
  - Issues an upgrade command to the on-demand broker.
  - Re-generates the service instance manifest based on its latest configuration from the tile.
  - Deploys the new manifest for the service instance.
  - Waits for this operation to complete, then proceeds to the next instance.
- Adds to a retry list any instances that have ongoing BOSH tasks at the time of upgrade.
- Retries any instances in the retry list until all are upgraded.

If any instance fails to upgrade, the errand fails immediately. This prevents  systemic problems from spreading to the rest of your service instances. 

#### <a id="delete-all"></a>Delete All Service Instances

This errand deletes all service instances of your broker’s service offering in every org and space of Cloud Foundry. It uses the Cloud Controller API to do this, and therefore only deletes instances the Cloud Controller knows about. It will not delete orphan BOSH deployments: those that don’t correspond to a known service instance. Orphan BOSH deployments should never happen, but in practice they might. Use the orphan-deployments errand to identify them.

The errand does the following:

- Unbinds all applications from the service instances.
- Deletes all service instances sequentially.
- Checks if any instances have been created while the errand was running.
    - If newly-created instances are detected, the errand fails.

<p class="note warning">
<strong>WARNING: </strong> This errand should only be used with extreme caution when you want to totally destroy all of the on-demand service instances in an environment.
</p>

Run this errand with the command `bosh run errand delete-all-service-instances` after you have selected the broker deployment with `bosh deployment`.

### <a id="detect-orphans"></a>Detect Orphaned Instances Service Instances

A service instance is defined as ‘orphaned’ when the BOSH deployment for the instance is still running, but the service is no longer registered in Cloud Foundry.

The `orphan-deployments` errand collates a list of service deployments that have no matching service instances in Cloud Foundry and return the list to the operator. It is then up to the operator to remove the orphaned bosh deployments.

Run this errand with the command `bosh run errand orphan-deployments` after you have selected the broker deployment with `bosh deployment`.

If orphan deployments exist, the errand outputs a list of deployment names:
<pre class="terminal">
[{"deployment\_name":"service-instance\_aoeu39fgn-8125-05h2-9023-9vbxf7676f3"}]
Errand 'orphan-deployments' completed successfully (exit code 0)
</pre>

To clean up orphaned instances, perform the following action on each:
<pre class="terminal">
$ bosh delete deployment SERVICE-INSTANCE-GUID
</pre>
<p class="note warning">
<strong>WARNING: </strong> This may leave IaaS resources in an unusable state.
</p>

### <a id="instance-deployment"></a>Select the BOSH Deployment for a Service Instance

1. Retrieve the the GUID of your service instance with command `cf service YOUR-SERVICE-INSTANCE --guid`.

1. Pre-pend the text `service_instance-` to the GUID you just obtained to create the ID that BOSH uses for your service instance (e.g. if your GUID is `1Hy6H`, this becomes `service_instance-1Hy6H`).

1. Run `bosh download manifest SERVICE-INSTANCE-GUID myservice.yml` to download your BOSH manifest for the service.

1. Run `bosh deployment myservice.yml` to select the deployment.

### <a id="instance-creds"></a>Get Admin Credentials for a Service Instance

1. [Identify the service deployment by GUID](#instance-deployment).
2. [Log into BOSH](https://docs.pivotal.io/pivotalcf/customizing/trouble-advanced.html#prepare).
3. [Download the manifest for the service instance](#access-instance) and add the GUID if using the v1 BOSH CLI.
4. Look in the manifest for the credentials, as described in the service documentation.

### <a id="reinstall"></a>Reinstall a Tile

To reinstall a tile in the same environment where it was previously uninstalled:

1. Ensure that the previous tile was correctly uninstalled as follows:
    1. `cf login` as an admin user.
    1. Run `cf m` and confirm that the Marketplace does not list the service.
    1. `bosh login` as an admin user.
    1. Run `bosh deployments` and confirm that its output does not show a deployment for the service. For example no `p-concourse-GUID` deployment exists.
1. Run the [`delete-all-service-instances`](#delete-all) errand to delete all instances of the service.
1. Run the [`deregister-broker`](#deregister-broker) errand to delete the service broker.
1. Run `bosh delete deployment YOUR-BROKER-DEPLOYMENT` to delete the service broker BOSH deployment.
1. Install the tile again.

### <a id="view-resources"></a>View Resource Saturation and Scaling

To view usage statistics for any service, select the service broker deployment. Then run `bosh vms --vitals` and `bosh instances --vitals` to view current resource utilization.

You can also view process-level information by using `bosh instances --ps`.

### <a id="id-instance-owner"></a>Identify Service Instance Owner

If you have spotted a failing service instance deployment, you can identify which org/space owns the instance and list the apps bound to it by following these steps:

1. `bosh vms SERVICE-INSTANCE-GUID` shows a VM in a failing state.
1. Take the deployment name and strip the `service-instance_` leaving you with the GUID.
1. Login to CF as an admin.
1. Run `cf curl /v2/service_instances/GUID | grep "space_url"` and record the SPACE-GUID field from the output `"space_url": "/v2/spaces/SPACE-GUID"`.
1. run `cf curl /v2/spaces/SPACE-GUID | grep -E "name|organization_url"` with the SPACE-GUID above and record from the output:
    1. The SPACE-NAME field from the output `"name": "MY-SPACE",` and
    1. The ORG-GUID field from the output `"organization_url": "/v2/organizations/ORG-GUID"`.
1. Run `cf curl  /v2/organizations/ORG-GUID | grep "name"` with the ORG-GUID above, and record the MY-ORG field from the output `"name": "MY-ORG"`.
1. Run `cf target -o MY-ORG -s MY-SPACE` with the values above to target the org and space.
1. Run `cf services` to see all the services and bound apps in the space.
6. Run `cf curl /v2/spaces/SPACE-GUID/managers` to find out who is the space manager.
7. Use this information to contact the space manager if needed.

### <a id="monitor-quota"></a>Monitor Quota Saturation and Service Instance Count

Quota saturation and total number of service instances are available through ODB metrics emitted to Loggregator. The metric names are shown below:

| **Metric Name**                                                           | **Description**                                           |
|---------------------------------------------------------------------------|-----------------------------------------------------------|
| `on-demand-broker/{service-name-marketplace}/quota_remaining`             | global quota remaining for all instances across all plans |
| `on-demand-broker/{service-name-marketplace}/{plan_name}/quota_remaining` | quota remaining for a particular plan                     |
| `on-demand-broker/{service-name-marketplace}/total_instances`             | total instances created across all plans                  |
| `on-demand-broker/{service-name-marketplace}/{plan_name}/total_instances` | total instances created for a given plan                  |

<p class="note"><strong>Note</strong>: Quota metrics are not emitted if no quota has been set.</p>

## <a id="support"></a>File a Support Ticket

You can file a support ticket [here](https://support.pivotal.io/). Be sure to provide the [error message](#parse-error) from `cf service YOUR-SERVICE-INSTANCE`.

To help expedite troubleshooting, also provide your [service broker logs](#access-broker), your [service instance logs](#access-instance) and [BOSH task output](#parse-error), if your `cf service YOUR-SERVICE-INSTANCE` output includes a `task-id`.

## <a id="kb"></a>Knowledge Base (Community)

Find the answer to your question and browse product discussions and solutions by searching the [Pivotal Knowledge Base](http://discuss.pivotal.io).
